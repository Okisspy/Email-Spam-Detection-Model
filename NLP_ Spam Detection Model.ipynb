{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset \n",
    "\n",
    "* from University of California Irvine Machine Learning Repository: [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [line.rstrip() for line in open('SMSSpamCollection')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first message\n",
    "\n",
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tOk lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the second message\n",
    "\n",
    "messages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tRofl. Its true to its name'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the last message\n",
    "\n",
    "messages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Length of messages\n",
    "\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: Collection of text is sometimes called a 'corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this is the place of encounter\n",
      "1 this is the place of surrneder\n",
      "2 do to me what you want Jesus\n"
     ]
    }
   ],
   "source": [
    "# Breakdown of collection of text or corpus\n",
    "\n",
    "list1 = ['this is the place of encounter',\n",
    "        'this is the place of surrneder',\n",
    "        'do to me what you want Jesus']\n",
    "\n",
    "for k, i in enumerate(list1):\n",
    "    print(k, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus of the first 7 messages in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "\n",
      "\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\n",
      "\n",
      "\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ...alongside the message number, we have:\n",
    "\n",
    "for message_no, message in enumerate(messages[:7]):\n",
    "    print(message_no, message)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "* From the 'Corpus' above, we can tell that the messages are separated with tabs, thus a 'tab-separated-value (tsv)' file.\n",
    "* first column   = label (ham or spam). ham and spam means 'good email' and 'bad email' respectively.\n",
    "* second column = the message itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to further show that the 'messages' file is a tsv,\n",
    "# let's check the first message\n",
    "\n",
    "\n",
    "messages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that the string above starts with \" __ham\\t__ \" meaning this is a 'good email', tab(__\" \\t \"__) and then the message itself\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* \"Hence we will rather use -> pandas <- to work on the dataset rather than regular python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset\n",
    "* as a 'csv' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2 = pd.read_csv(filepath_or_buffer = 'SMSSpamCollection', \n",
    "                        sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  \\\n",
       "0      ham   \n",
       "1     spam   \n",
       "2      ham   \n",
       "3      ham   \n",
       "4     spam   \n",
       "...    ...   \n",
       "5566  spam   \n",
       "5567   ham   \n",
       "5568   ham   \n",
       "5569   ham   \n",
       "5570   ham   \n",
       "\n",
       "     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...  \n",
       "0                         Ok lar... Joking wif u oni...                                                               \n",
       "1     Free entry in 2 a wkly comp to win FA Cup fina...                                                               \n",
       "2     U dun say so early hor... U c already then say...                                                               \n",
       "3     Nah I don't think he goes to usf, he lives aro...                                                               \n",
       "4     FreeMsg Hey there darling it's been 3 week's n...                                                               \n",
       "...                                                 ...                                                               \n",
       "5566  This is the 2nd time we have tried 2 contact u...                                                               \n",
       "5567               Will ü b going to esplanade fr home?                                                               \n",
       "5568  Pity, * was in mood for that. So...any other s...                                                               \n",
       "5569  The guy did some bitching but I acted like i'd...                                                               \n",
       "5570                         Rofl. Its true to its name                                                               \n",
       "\n",
       "[5571 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2\n",
    "\n",
    "\n",
    "\n",
    "# To see the entire datafram\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Rename the columns:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2.columns = ['label', 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham                      Ok lar... Joking wif u oni...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  U dun say so early hor... U c already then say...\n",
       "3   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "4  spam  FreeMsg Hey there darling it's been 3 week's n..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2.head()\n",
    "\n",
    "\n",
    "# this is a nice dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "#### Statistical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5571</td>\n",
       "      <td>5571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4824</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5571                    5571\n",
       "unique     2                    5168\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4824                      30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 5571 label counts (ham & spam) and 5571 messages counted\n",
    "* There are 2 unique labels (ham -> good email, and spam -> bad email)\n",
    "* There are 5168 unique messages and this makes sense to be less than the count (5571)\n",
    "* ... because, we could have repetitions in the messages;\n",
    "* ... In this case, there are 5571-5168 = 403 repeated messages\n",
    "* The 'top' label (the most common label) is 'ham' with 4824 freq/repetitioins\n",
    "* The 'top' message (the most common message) is \"Sorry, I'll call later\" with 30 freq/repetitions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check the statistics of both labels i.e. 'spam' and 'ham' messages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4824</td>\n",
       "      <td>4515</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4824   4515                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For 'ham'*\n",
    "* There are 4824 good emails of which 4515 are unique, which implies 309 repeated emails\n",
    "* The 'top' message (the most common message) is \"Sorry, I'll call later\" and was repeated 30 times (i.e. frequency) \n",
    "\n",
    "*For 'spam'*\n",
    "* There are 747 good emails of which 653 are unique, which implies 94 repeated emails\n",
    "* The 'top' message (the most common message) is \"Please call our customer service representative\" and was repeated 4 times (i.e. frequency) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance the Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We currently have an unbalanced dataset with 4824 good email (ham) and 747 bad emails (spam), which will make out prediction skewed towards 'ham'. We seek to balance the dataset by taking equal sample sizes of both 'ham' and 'spam'.\n",
    "\n",
    "* Currently, the total email messages is 5,574 but after making the dataset balance, we expect 747 from each category making our total to be 1,494.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out all the 'ham' and 'spam' messages separately\n",
    "ham_messages = messages2.loc[messages2['label'].isin(['ham'])]\n",
    "spam_messages = messages2.loc[messages2['label'].isin(['spam'])]\n",
    "\n",
    "\n",
    "# Now collect a random sample of 747 for 'ham'\n",
    "ham_messages = ham_messages.sample(n = 747, replace = True)\n",
    "\n",
    "# The 'spam' messages is already 747. So no extraction here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah sure I'll leave in a min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ham</td>\n",
       "      <td>Going for dinner.msg you after.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>ham</td>\n",
       "      <td>awesome, how do I deal with the gate? Charles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>ham</td>\n",
       "      <td>My love ... I hope your not doing anything dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>ham</td>\n",
       "      <td>You got called a tool?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pete can you please ring meive hardly gotany c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've told him that i've returned it. That shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh ho. Is this the first time u use these type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>ham</td>\n",
       "      <td>It could work, we'll reach a consensus at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u send wrongly lar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "3574   ham                      Yeah sure I'll leave in a min\n",
       "111    ham                    Going for dinner.msg you after.\n",
       "3439   ham  awesome, how do I deal with the gate? Charles ...\n",
       "4233   ham  My love ... I hope your not doing anything dra...\n",
       "280    ham                             You got called a tool?\n",
       "...    ...                                                ...\n",
       "587    ham  Pete can you please ring meive hardly gotany c...\n",
       "2799   ham  I've told him that i've returned it. That shou...\n",
       "3310   ham  Oh ho. Is this the first time u use these type...\n",
       "1860   ham  It could work, we'll reach a consensus at the ...\n",
       "974    ham                           Eh u send wrongly lar...\n",
       "\n",
       "[747 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check both messages\n",
    "\n",
    "ham_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>747 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "4     spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "7     spam  WINNER!! As a valued network customer you have...\n",
       "8     spam  Had your mobile 11 months or more? U R entitle...\n",
       "10    spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "...    ...                                                ...\n",
       "5536  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5539  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5546  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5565  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5566  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[747 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join the 'ham' and 'spam' to get a full dataset\n",
    "\n",
    "* This will be the updated \"messages2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeah sure I'll leave in a min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ham</td>\n",
       "      <td>Going for dinner.msg you after.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>ham</td>\n",
       "      <td>awesome, how do I deal with the gate? Charles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>ham</td>\n",
       "      <td>My love ... I hope your not doing anything dra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>ham</td>\n",
       "      <td>You got called a tool?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "3574   ham                      Yeah sure I'll leave in a min\n",
       "111    ham                    Going for dinner.msg you after.\n",
       "3439   ham  awesome, how do I deal with the gate? Charles ...\n",
       "4233   ham  My love ... I hope your not doing anything dra...\n",
       "280    ham                             You got called a tool?\n",
       "...    ...                                                ...\n",
       "5536  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5539  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5546  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5565  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5566  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_dataset = pd.concat([ham_messages, spam_messages])\n",
    "\n",
    "# update 'messages2'\n",
    "messages2 = balanced_dataset\n",
    "messages2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>ham</td>\n",
       "      <td>Alex knows a guy who sells mids but he's down ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have WON a guaranteed £1000 cash or a £200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you go tell your friend you're not s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have 1 new message. Call 0207-083-6089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm serious. You are in the money base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>ham</td>\n",
       "      <td>K, want us to come by now?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>ham</td>\n",
       "      <td>Babe! I fucking love you too !! You know? Fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thinkin about someone is all good. No drugs fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aldrine, rakhesh ex RTM here.pls call.urgent.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "5539  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "2287   ham  Alex knows a guy who sells mids but he's down ...\n",
       "718   spam  You have WON a guaranteed £1000 cash or a £200...\n",
       "776    ham  Why don't you go tell your friend you're not s...\n",
       "5380  spam         You have 1 new message. Call 0207-083-6089\n",
       "...    ...                                                ...\n",
       "3511   ham             I'm serious. You are in the money base\n",
       "1767   ham                         K, want us to come by now?\n",
       "5179   ham  Babe! I fucking love you too !! You know? Fuck...\n",
       "2811   ham  Thinkin about someone is all good. No drugs fo...\n",
       "3727   ham      Aldrine, rakhesh ex RTM here.pls call.urgent.\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2 = shuffle(messages2)\n",
    "\n",
    "messages2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Re-check the statistics of both labels i.e. 'spam' and 'ham' messages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>747</td>\n",
       "      <td>681</td>\n",
       "      <td>I cant pick the phone right now. Pls send a me...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham       747    681  I cant pick the phone right now. Pls send a me...    6\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let us do some Feature Engineering\n",
    "\n",
    "##### Definition:\n",
    "\n",
    "**Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning and is both difficult and expensive. **\n",
    "\n",
    "(source: https://towardsdatascience.com/exploratory-data-analysis-feature-engineering-and-modelling-using-supermarket-sales-data-part-1-228140f89298)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long are the text messages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-ce5f36531d15>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  messages2['length'] = messages2['message'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "# Create a new column on the dataset to account for email/message length\n",
    "\n",
    "\n",
    "messages2['length'] = messages2['message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>ham</td>\n",
       "      <td>Alex knows a guy who sells mids but he's down ...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have WON a guaranteed £1000 cash or a £200...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you go tell your friend you're not s...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have 1 new message. Call 0207-083-6089</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm serious. You are in the money base</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>ham</td>\n",
       "      <td>K, want us to come by now?</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>ham</td>\n",
       "      <td>Babe! I fucking love you too !! You know? Fuck...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thinkin about someone is all good. No drugs fo...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aldrine, rakhesh ex RTM here.pls call.urgent.</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "5539  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...     158\n",
       "2287   ham  Alex knows a guy who sells mids but he's down ...     110\n",
       "718   spam  You have WON a guaranteed £1000 cash or a £200...     145\n",
       "776    ham  Why don't you go tell your friend you're not s...     145\n",
       "5380  spam         You have 1 new message. Call 0207-083-6089      42\n",
       "...    ...                                                ...     ...\n",
       "3511   ham             I'm serious. You are in the money base      38\n",
       "1767   ham                         K, want us to come by now?      26\n",
       "5179   ham  Babe! I fucking love you too !! You know? Fuck...     157\n",
       "2811   ham  Thinkin about someone is all good. No drugs fo...      52\n",
       "3727   ham      Aldrine, rakhesh ex RTM here.pls call.urgent.      45\n",
       "\n",
       "[1494 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the length of the messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the distribution of message length\n",
    "\n",
    "* Note that the bin size has effect on the nature of the distribution\n",
    "* For more detail, you can increase the bin-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24e8a2148b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages2['length'].plot.hist(bins = 150)\n",
    "\n",
    "#plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can observe that there are a few outliers, implying that there are \n",
    "* ...some messages that are really long, having above 800 characters (including space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the maximum and minimum email message length ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1494.000000\n",
       "mean      105.139224\n",
       "std        59.720117\n",
       "min         4.000000\n",
       "25%        50.000000\n",
       "50%       119.500000\n",
       "75%       152.750000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The maximum email message is 910 characters long\n",
    "* The minimum email message is just 4 character long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the email message of the maximum =910 character long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "1084   ham  For me the love should start with attraction.i...     910"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2[messages2['length'] == 910]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print the entire \"message\" alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2[messages2['length'] == 910]['message'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the email message of the minimum =2 character long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>ham</td>\n",
       "      <td>Okie</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>ham</td>\n",
       "      <td>Okie</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label message  length\n",
       "2687   ham    Okie       4\n",
       "3900   ham    Okie       4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2[messages2['length'] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print the entire \"message\" alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okie\n",
      "Okie\n"
     ]
    }
   ],
   "source": [
    "# we have 2 of this messages. \n",
    "# We want to print all 2\n",
    "\n",
    "total_messages = len(messages2[messages2['length'] == 4])\n",
    "\n",
    "for i in range(total_messages):\n",
    "    print(messages2[messages2['length'] == 4]['message'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is message length a distinguishing feature between 'ham' and 'spam'?\n",
    "\n",
    "## can we use length to determine a spam or ham email?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x0000024E8A533AC0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x0000024E8A53C250>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use pandas version of facet-grid (seaborn can do this too)\n",
    "\n",
    "messages2.hist(column  = 'length', \n",
    "               by      = 'label', \n",
    "               bins    =  200, \n",
    "               figsize = (12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'ham' emails are centered around 50 characters with a range of 0 to 200\n",
    "* 'spam' emails are centered around 150 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion on email message length:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By visualization, we can tell that 'length of emails/messages' can be used\n",
    "* ... as a good feature to distinguish 'ham' and 'spam' emails\n",
    "\n",
    "\n",
    "\n",
    "* The margin is really wide. By averages: 50 - 150 (or 1:3 -ham:spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the text (email messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We want to convert of corpus of strings to a vector format using the Bag of words approach (i.e. each unique word in a text is represented by one number)\n",
    "\n",
    "* So, we basically are converting the raw messages (a sequence of characters) into vectors (a sequence of numbers)\n",
    "\n",
    "* ...to do this, we split the words in a string and store it in a list and remove stop words (like \"the\", \"is\", \"and\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check punctuations in string-library\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the stop words\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many common stopwords do we have in this library?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the list of these common English \"stop-words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>ham</td>\n",
       "      <td>Alex knows a guy who sells mids but he's down ...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have WON a guaranteed £1000 cash or a £200...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you go tell your friend you're not s...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>spam</td>\n",
       "      <td>You have 1 new message. Call 0207-083-6089</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "5539  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...     158\n",
       "2287   ham  Alex knows a guy who sells mids but he's down ...     110\n",
       "718   spam  You have WON a guaranteed £1000 cash or a £200...     145\n",
       "776    ham  Why don't you go tell your friend you're not s...     145\n",
       "5380  spam         You have 1 new message. Call 0207-083-6089      42"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall original messages\n",
    "\n",
    "messages2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize these mesages\n",
    "* This converting a normal text string into a list of tokens (cleaned version of the words we actually want)\n",
    "* This process removes the stop words and gives us a list of the words of interest\n",
    "\n",
    "\n",
    "* Next, let us define a function to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. remove punctuations\n",
    "    2. remmove stop words\n",
    "    3. return list of clean text words\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # using list comprehension\n",
    "    no_punctuation = [char for char in mess if char not in string.punctuation]\n",
    "    \n",
    "    \n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "    \n",
    "    clean_text = [word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return clean_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5539    [ASKED, 3MOBILE, 0870, CHATLINES, INCLU, FREE,...\n",
       "2287    [Alex, knows, guy, sells, mids, hes, south, ta...\n",
       "718     [guaranteed, £1000, cash, £2000, prize, claim,...\n",
       "776     [dont, go, tell, friend, youre, sure, want, li...\n",
       "5380                 [1, new, message, Call, 02070836089]\n",
       "                              ...                        \n",
       "3511                           [Im, serious, money, base]\n",
       "1767                                  [K, want, us, come]\n",
       "5179    [Babe, fucking, love, know, Fuck, good, hear, ...\n",
       "2811                      [Thinkin, someone, good, drugs]\n",
       "3727     [Aldrine, rakhesh, ex, RTM, herepls, callurgent]\n",
       "Name: message, Length: 1494, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2['message'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5539    [ASKED, 3MOBILE, 0870, CHATLINES, INCLU, FREE,...\n",
       "2287    [Alex, knows, guy, sells, mids, hes, south, ta...\n",
       "718     [guaranteed, £1000, cash, £2000, prize, claim,...\n",
       "776     [dont, go, tell, friend, youre, sure, want, li...\n",
       "5380                 [1, new, message, Call, 02070836089]\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grab the first 5\n",
    "\n",
    "messages2['message'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* convert each message into a vector that machine learning (or the SciKit Learn algorithms) models  can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us see how this \"CountVectorizer\" works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_transformer = CountVectorizer(analyzer = text_process).fit(messages2['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bag of word counts for a sample email:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know u and u don't know me. Send CHAT to 86688 now and let's find each other! Only 150p/Msg rcvd. HG/Suite342/2Lands/Row/W1J6HL LDN. 18 years or over.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an object to store the sample message, say 'email_sample' having index 2412\n",
    "\n",
    "email_sample = messages2['message'][2412]\n",
    "email_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_3 = bag_of_words_transformer.transform([email_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 346)\t1\n",
      "  (0, 373)\t1\n",
      "  (0, 727)\t1\n",
      "  (0, 1003)\t1\n",
      "  (0, 1388)\t1\n",
      "  (0, 1574)\t1\n",
      "  (0, 2144)\t1\n",
      "  (0, 3235)\t2\n",
      "  (0, 3413)\t1\n",
      "  (0, 3843)\t2\n",
      "  (0, 3902)\t1\n",
      "  (0, 4474)\t1\n",
      "  (0, 5095)\t2\n",
      "  (0, 5390)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* This means that there are 14 unique words in sample message, after removing the stop words, three of these unique words appeared twice and we can easily confirm that using the \"index\" under the feature names (check next code...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dont'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_transformer.get_feature_names()[3235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'know'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_transformer.get_feature_names()[3843]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_transformer.get_feature_names()[5095]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the \".transform\" to the entire 'message' column in the dataframe rather one sample message (illustrated above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease:\n",
    "bow_transformer = bag_of_words_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2_bow = bow_transformer.transform(messages2['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1494x5478 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 18064 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* We see that the vector of the entire email message is represented as a \"Sparse Matrix\" (a matrix that contains more number of ZERO values than NON-ZERO values)\n",
    "\n",
    "* We have 18064 elements that are compressed in row format. These are the number of NON-ZERO elements \n",
    "\n",
    "Source/more on __Sparse Matrix__: http://www.btechsmartclass.com/data_structures/sparse-matrix.html#:~:text=Sparse%20matrix%20is%20a%20matrix,only%2010%20non%2Dzero%20elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1494, 5478)\n"
     ]
    }
   ],
   "source": [
    "print(messages2_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many non-zero elements in the Sparse Matrix do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18064\n"
     ]
    }
   ],
   "source": [
    "print(messages2_bow.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Sparsity?\n",
    "* This is basically comparing the number of non-zero elements (messages) to the zero elements. \n",
    "\n",
    "* We use a formula to do this: (number of zero elements/total number of elements (m-by-n matrix) )\n",
    "\n",
    "* The density is 1 - sparsity. This compares the number of zero elements to the non-zero elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in percentage is 0.2207% \n",
      "\n",
      "\n",
      "Density in percentage is 0.7793 % \n"
     ]
    }
   ],
   "source": [
    "sparsity = (messages2_bow.nnz / (messages2_bow.shape[0] * messages2_bow.shape[1]))\n",
    "\n",
    "sparsity\n",
    "\n",
    "print(\"Sparsity in percentage is {}% \".format(round(sparsity*100.0, 4)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Density in percentage is {} % \".format(1 - round(sparsity*100.0, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "* With such a sparsity value, it is clear that the number of zeros in the matrix is high. This is evident in the high value of the Density (closer to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 and Step 3:\n",
    "\n",
    "* We use the TF-IDF\n",
    "* __TF-IDF__ means __Term Frequency- Inverse Document Frequency:__ The _tf-idf_ weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The __tf-idf weight__ is composed by two(2) terms: \n",
    "    * the first computes the normalized Term Frequency (TF): the number of times a word appears in a document, divided by the total number of words in that document (i.e. email)\n",
    "    \n",
    "        * **TF('word') = (Number of times term 'word' appears in a document) / (Total number of terms in the document).**\n",
    "                \n",
    "    * the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents (e.g. emails) in the corpus divided by the number of documents where the specific term appears.\n",
    "        * **IDF('word') = log_e(Total number of documents / Number of documents with term 'word' in it).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Therefore, final value is gotten as:\n",
    "                     **TF-IDF = TF('word') * IDF('word')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>> Let us see how this \"Tfidf Transformer\" works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease, let:\n",
    "\n",
    "bow_transformer = bag_of_words_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Apply the \".transform\" to the entire 'message' column in the dataframe rather one sample message (illustrated above)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2_bow = bow_transformer.transform(messages2['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(messages2_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform just one message to get the Inverse Document Frequency and\n",
    "# Term Frequency (TF) relationship for email_sample (i.e. example used previously)\n",
    "\n",
    "\n",
    "tfidf3 = tfidf_transformer.transform(bag_of_words_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5390)\t0.2530024609593074\n",
      "  (0, 5095)\t0.2720147207017997\n",
      "  (0, 4474)\t0.2578774929341825\n",
      "  (0, 3902)\t0.2697846346883843\n",
      "  (0, 3843)\t0.35923064479985967\n",
      "  (0, 3413)\t0.21071638409659496\n",
      "  (0, 3235)\t0.38048187941091627\n",
      "  (0, 2144)\t0.21416754331854163\n",
      "  (0, 1574)\t0.2578774929341825\n",
      "  (0, 1388)\t0.2865668084174612\n",
      "  (0, 1003)\t0.2318594225279512\n",
      "  (0, 727)\t0.21995228077374937\n",
      "  (0, 373)\t0.1873180833175463\n",
      "  (0, 346)\t0.2697846346883843\n"
     ]
    }
   ],
   "source": [
    "print(tfidf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "   * The numbers are the weight values for each of these words versus the actual document\n",
    "   * Recall, these words can be seen using their index, as previously illustrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know u and u don't know me. Send CHAT to 86688 now and let's find each other! Only 150p/Msg rcvd. HG/Suite342/2Lands/Row/W1J6HL LDN. 18 years or over.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall the email_sample under consideration\n",
    "\n",
    "email_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the term frequency- inverse document frequency weight of 'CHAT' in sample_email ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, check which index represents 'CHAT'\n",
    "\n",
    "bag_of_words_transformer.vocabulary_['CHAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "* The result vectors are arranged in descending order of the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "The term frequency-inverse document frequency weight of 'say' in email3 is gotten from\n",
    "\n",
    "   _(0, 977)  -->\t0.23248663263329686_ and is approximately __0.2325__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's explore OUTSIDE of email_sample:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the Inverse Document Frequency (IDF) of \"house\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.230439944144951"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['house']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.616734305264841"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer.idf_[bow_transformer.vocabulary_['pictures']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 'spam' and 'ham' classifier\n",
    "* Many other classifiers can be used but we want to use the Naive-Bayes classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we convert the entire bag of word corpus into a tfidf corpus at once.\n",
    "# This similar to what we did with bow_of_words_3 (for email_sample)\n",
    "\n",
    "\n",
    "\n",
    "tfidf_all_messages = tfidf_transformer.transform(messages2_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==>> Let us see how this \"MultinomialNB\" works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(X = tfidf_all_messages,\n",
    "                                        y = messages2['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Classify a single random message to see how the prediction will do:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(tfidf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(tfidf3)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "* The model detects that the 'email_sample' message will be 'ham' (good message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check if the above prediction is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2['label'][2412]  # from the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:\n",
    "* Yes, our model seems to be predicting correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's do this prediction for all the emails in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_all = spam_detect_model.predict(tfidf_all_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data to Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(messages2['message'], \n",
    "                                                    messages2['label'], \n",
    "                                                    test_size    = 0.20,   # using 20% as test_data\n",
    "                                                    random_state = 42)\n",
    "# Notes:\n",
    "# X represents 'message'\n",
    "# y represents 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* Now we would use \"Pipeline\" rather doing all the long previous steps we went through\n",
    "* To do this:\n",
    "    * Pass in a list of _everything_ you want to do into the 'Pipeline'\n",
    "    * _everything_ here would mean a tuple having ('name of step', 'calculation/function of that step')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bag of words', CountVectorizer(analyzer = text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Train on Model', MultinomialNB())  # you can change this 'Classifier' e.g. to RandomForestClassfier etc\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag of words',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x0000024E8AAF7820>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('Train on Model', MultinomialNB())])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pipeline.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the Prediction of the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'spam',\n",
       "       'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'spam', 'ham',\n",
       "       'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam',\n",
       "       'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham',\n",
       "       'spam', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam',\n",
       "       'spam', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam',\n",
       "       'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam', 'ham',\n",
       "       'ham', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam',\n",
       "       'spam', 'spam', 'spam', 'ham', 'spam', 'spam', 'spam', 'ham',\n",
       "       'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam',\n",
       "       'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham',\n",
       "       'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam',\n",
       "       'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham',\n",
       "       'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham',\n",
       "       'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham',\n",
       "       'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'ham', 'ham',\n",
       "       'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham',\n",
       "       'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham',\n",
       "       'ham', 'spam', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham',\n",
       "       'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham',\n",
       "       'ham', 'spam', 'spam', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham',\n",
       "       'spam', 'ham', 'ham', 'spam', 'spam', 'ham', 'spam', 'spam', 'ham',\n",
       "       'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam',\n",
       "       'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'spam',\n",
       "       'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham',\n",
       "       'spam', 'ham', 'ham', 'spam', 'spam', 'ham', 'spam', 'spam',\n",
       "       'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'ham',\n",
       "       'spam', 'ham', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam',\n",
       "       'spam', 'spam', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam',\n",
       "       'spam', 'spam', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam',\n",
       "       'spam'], dtype='<U4')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "                                                  Predicted\n",
    "                     -------------------------------------------------------------------\n",
    "                    |       ham                        |        spam                   \n",
    "           |-----------------------------------------------------------------------------\n",
    "    Actual |ham     |  True ham  (True Negative)       |    False spam (False Positive)   \n",
    "           |spam    |  False ham (False Negative)      |    True spam  (True Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136   8]\n",
      " [ 12 143]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true = y_test, \n",
    "                       y_pred = predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.94      0.93       144\n",
      "        spam       0.95      0.92      0.93       155\n",
      "\n",
      "    accuracy                           0.93       299\n",
      "   macro avg       0.93      0.93      0.93       299\n",
      "weighted avg       0.93      0.93      0.93       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, \n",
    "                            y_pred = predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "\n",
    "* Generally, the accuracy of the model seems very good being 93% accurate. But, our focus will not be on _Accuracy_, rather will be on _Precision_.\n",
    "\n",
    "\n",
    "* **<u>Precision:</u>** is a good measure to determine, when we prioritize the costs of False-Positive. If we take Positive to mean 'spam' and Negative to mean 'ham'; then a false positive would mean that a ham or good email (actual negative) has been identified as spam or bad email (predicted spam). **_The result of this becomes that the email user might lose important emails if the precision is not high for the model._**\n",
    "\n",
    "\n",
    "* ham:\n",
    "    * The _Precision_ is 92% which tells very well on our model in classifying good emails.\n",
    "   \n",
    "    \n",
    "* spam:\n",
    "    * The _Precision_ is 95% which tells us that our model is doing fine in detecting spam emails, although not as 'ham'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumming we wanted to predict new email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_email = ['I am so grateful and excited. I got my the Job! Hurray!!!!!!']\n",
    "\n",
    "pipeline.predict(new_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_email2 = ['We will give you $1,000 for sending an e-mail to your friends.  AB Mailing, Inc. is proud to anounce the start of a new contest.  Each day untilJanuary, 31 1999, one lucky Internet or AOL user who forwards our advertisement to their friends will be randomly picked to receive $1,000!  You could be the winner!']\n",
    "\n",
    "pipeline.predict(new_email2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This example is from MIT: http://web.mit.edu/network/spam/examples/\n",
    "# Specifically example \"Jan 1999\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: \n",
    "\n",
    "* We can change the 'Train on Model -Classifier' (currently Naive Bayes) to other types of classifiers or ensemble methods\n",
    "    * Other Classifiers:\n",
    "        * Decision Tree,\n",
    "        * K-Nearest Neigbor\n",
    "        * Artificial Neural Networks\n",
    "        * Logistic Regression\n",
    "        * Support Vector Machine etc\n",
    "        * Ensemble methods:\n",
    "                * Random Forest\n",
    "                * Bagging etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the *Logistic Regression* classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bag of words', CountVectorizer(analyzer = text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Train on Model', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag of words',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x0000024E8AAF7820>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('Train on Model', LogisticRegression())])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.91      0.96      0.93       144\n",
      "        spam       0.96      0.91      0.93       155\n",
      "\n",
      "    accuracy                           0.93       299\n",
      "   macro avg       0.93      0.93      0.93       299\n",
      "weighted avg       0.93      0.93      0.93       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, \n",
    "                            y_pred = predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Ensemble method of classifier: *_Random Forest_* classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bag of words', CountVectorizer(analyzer = text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Train on Model', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bag of words',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x0000024E8AAF7820>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('Train on Model', RandomForestClassifier())])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      1.00      0.94       144\n",
      "        spam       1.00      0.88      0.94       155\n",
      "\n",
      "    accuracy                           0.94       299\n",
      "   macro avg       0.94      0.94      0.94       299\n",
      "weighted avg       0.95      0.94      0.94       299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, \n",
    "                            y_pred = predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding Thoughts:\n",
    "* Some Data Scientist prefer to use an ensembler method for classification often because _it is a set of classifiers whose individual decisions are combined in some way to classify new examples_. \n",
    "\n",
    "\n",
    "* From our few trials of both _single classifiers_ and _set of classifiers_ (ensembler method) does well. I will give preference to the Logistic Regression Classifier, simply because it balances giving a higher prediction for 'spam' and not lowering the prediction for 'ham' so much. Recall our attention is still on _Precision_.\n",
    "\n",
    "\n",
    "* I did not choose RandomForestClassifier as my preferred because, although the 'spam'-detection precision is very high or seems perfect, I think, it lowered so much of the 'ham' precision. Again, this is just my preference.\n",
    "\n",
    "\n",
    "* As a future step, I will want to try other classifiers. In my opinion, choosing the classifier would depend mostly on the Data Scientist or Team  and what they want to achieve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
